{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 1\n",
    "Find a Twitter data archive of your choice.  Some places to look for free Twitter data include:\n",
    "ArchiveTeam JSON Download of Twitter Stream: https://archive.org/details/archiveteam-twitter-stream-2017-11\n",
    "ICWSM Conference Datasets: http://www.icwsm.org/2015/datasets/datasets/\n",
    "Library of Congress Twitter Archive: https://blogs.loc.gov/loc/2010/04/how-tweet-it-is-library-acquires-entire-twitter-archive/\n",
    "https://github.com/jdorfman/awesome-json-datasets \n",
    "Download at least 5 files worth of tweets into a folder on your hard drive\n",
    "Write a Python script that will:\n",
    "Iterate through all the files you downloaded\n",
    "Read the data\n",
    "Convert the data to csv format\n",
    "Save combined data into a single CSV file\n",
    "\n",
    "Challenge 2\n",
    "Carefully review the data and think about what kinds of MEANINGFUL questions you can ask of the data and answer with the data. \n",
    "Come up a meaningful question that you can answer with your data.\n",
    "Make sure that your Python script comments contain:\n",
    "    The question you are asking\n",
    "    The reason you decided to ask that particular question\n",
    "    Briefly describe your algorithm for addressing your question\n",
    "    What knowledge you will gain from answering your question\n",
    "Implement a solution required for answering your question in the same script you created for Challenge 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1:\n",
    "\n",
    "# import csv and pandas to use the .read_json and .to_csv methods\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# get all the json tweets\n",
    "df24 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-24.json\", \n",
    "                    typ = 'frame')\n",
    "df25 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-25.json\", \n",
    "                    typ = 'frame')\n",
    "df26 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-26.json\", \n",
    "                    typ = 'frame')\n",
    "df27 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-27.json\", \n",
    "                    typ = 'frame')\n",
    "df28 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-28.json\", \n",
    "                    typ = 'frame')\n",
    "df29 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-29.json\", \n",
    "                    typ = 'frame')\n",
    "df30 = pd.read_json(\"/Users/rgurewitsch/Desktop/congress_tweets/2018-01-30.json\", \n",
    "                    typ = 'frame')\n",
    "\n",
    "# bring em all together\n",
    "frames = [df24, df25, df26, df27, df28, df29, df30]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# export to csv file\n",
    "df.to_csv(\"/Users/rgurewitsch/Desktop/all_tweets.csv\")\n",
    "\n",
    "# test: df.head() should show tweets from 2018-01-24 and df.tail() from 2018-01-28\n",
    "# df.head()\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>958550973848391680</td>\n",
       "      <td>https://www.twitter.com/elizabethforma/statuse...</td>\n",
       "      <td>elizabethforma</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>America’s moral fabric isn’t stronger when @re...</td>\n",
       "      <td>2018-01-30T23:02:15-05:00</td>\n",
       "      <td>357606935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>958550964511952896</td>\n",
       "      <td>https://www.twitter.com/SenFeinstein/statuses/...</td>\n",
       "      <td>SenFeinstein</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Read my comments on the president’s State of t...</td>\n",
       "      <td>2018-01-30T23:02:13-05:00</td>\n",
       "      <td>476256944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>958550945415286784</td>\n",
       "      <td>https://www.twitter.com/SenatorFischer/statuse...</td>\n",
       "      <td>SenatorFischer</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>I’ve been a leader on #Infrastructure issues -...</td>\n",
       "      <td>2018-01-30T23:02:09-05:00</td>\n",
       "      <td>1071402577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7327</th>\n",
       "      <td>958550937932587008</td>\n",
       "      <td>https://www.twitter.com/Perduesenate/statuses/...</td>\n",
       "      <td>Perduesenate</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Joining @trish_regan on Fox Business shortly t...</td>\n",
       "      <td>2018-01-30T23:02:07-05:00</td>\n",
       "      <td>1397501864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>958550937706156032</td>\n",
       "      <td>https://www.twitter.com/SenSanders/statuses/95...</td>\n",
       "      <td>SenSanders</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>Here's the story that Trump failed to mention:...</td>\n",
       "      <td>2018-01-30T23:02:07-05:00</td>\n",
       "      <td>29442313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               link  \\\n",
       "7324  958550973848391680  https://www.twitter.com/elizabethforma/statuse...   \n",
       "7325  958550964511952896  https://www.twitter.com/SenFeinstein/statuses/...   \n",
       "7326  958550945415286784  https://www.twitter.com/SenatorFischer/statuse...   \n",
       "7327  958550937932587008  https://www.twitter.com/Perduesenate/statuses/...   \n",
       "7328  958550937706156032  https://www.twitter.com/SenSanders/statuses/95...   \n",
       "\n",
       "         screen_name              source  \\\n",
       "7324  elizabethforma  Twitter Web Client   \n",
       "7325    SenFeinstein  Twitter Web Client   \n",
       "7326  SenatorFischer           TweetDeck   \n",
       "7327    Perduesenate  Twitter for iPhone   \n",
       "7328      SenSanders           TweetDeck   \n",
       "\n",
       "                                                   text  \\\n",
       "7324  America’s moral fabric isn’t stronger when @re...   \n",
       "7325  Read my comments on the president’s State of t...   \n",
       "7326  I’ve been a leader on #Infrastructure issues -...   \n",
       "7327  Joining @trish_regan on Fox Business shortly t...   \n",
       "7328  Here's the story that Trump failed to mention:...   \n",
       "\n",
       "                           time     user_id  \n",
       "7324  2018-01-30T23:02:15-05:00   357606935  \n",
       "7325  2018-01-30T23:02:13-05:00   476256944  \n",
       "7326  2018-01-30T23:02:09-05:00  1071402577  \n",
       "7327  2018-01-30T23:02:07-05:00  1397501864  \n",
       "7328  2018-01-30T23:02:07-05:00    29442313  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n",
    "# Question: How dominant was the issue of DACA to Congress in January \n",
    "#           immediately after the government shutdown and then reopened?\n",
    "# Why:      The issue of the Dreamers, or hispanic immigrants who were brought to America as \n",
    "#           children, became particularly prominent in the national conversation when the\n",
    "#           Congress started to reach it's deadline to pass a budget. President Donald Trump \n",
    "#           was threatening to let the government shut down if Congress' budget bill did \n",
    "#           not take a more hardline approach to immigration. So how were our Congressmen \n",
    "#           and women reacting to this situation on Twitter?\n",
    "# Description of algorithm:\n",
    "#           The algorithm I will design will take the text from each of the tweets, analyze\n",
    "#           the frequency with which each hashtag occurs, and compare hashtags associated \n",
    "#           with the DACA issue and compare them to the frequency of other unrelated hashtags.\n",
    "#           This will allow us to see what is \"trending\" and whether DACA was the most talked\n",
    "#           about issue during the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reg ex to help find the hashtags\n",
    "import re\n",
    "\n",
    "# populate text_tweets with the string values from 'text' \n",
    "text_tweets = df[\"text\"]\n",
    "# print to test\n",
    "# print(text_tweets)\n",
    "\n",
    "# for punctuation marks\n",
    "punctuation_marks = ['!','.', ',', ':', ';', '?', '-', '\\n']\n",
    "\n",
    "# list of hashtags\n",
    "hashes = []\n",
    "\n",
    "# find the hashtags!\n",
    "for tweet in text_tweets:\n",
    "    # replace all punctuation with spaces\n",
    "    for pm in punctuation_marks:\n",
    "        tweet = tweet.replace(pm, ' ')\n",
    "        \n",
    "    # re looks for strings starting with a #\n",
    "    x = re.findall(r\"#(\\w+)\", tweet)\n",
    "    \n",
    "    # put hashtags into hashes\n",
    "    counter = 0\n",
    "    for i in x:\n",
    "        hashes.append(x[counter])\n",
    "        counter += 1\n",
    "        \n",
    "    \n",
    "# print to test if hashes is filled with hashtags\n",
    "#print(hashes[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's that function that finds frequency of a word in a list\n",
    "def find_freq(word, wlist):\n",
    "    # Now, let's find the frequency\n",
    "    freq = 0\n",
    "    for n in range(0, len(wlist)):\n",
    "        if word == wlist[n]:\n",
    "            freq = freq + 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Congressional tweets between January 24 and 30:\n",
      "#DACA appeared 156 times\n",
      "#Dreamers appeared 143 times\n",
      "#ProtectDreamers appeared 48 times\n",
      "2% of all hashtags were DACA related\n"
     ]
    }
   ],
   "source": [
    "# find the frequency of #DACA, #Dreamers, #ProtectDreamers\n",
    "_DACA = find_freq(\"DACA\", hashes)\n",
    "_Dreamers = find_freq(\"Dreamers\", hashes)\n",
    "_ProtectDreamers = find_freq(\"ProtectDreamers\", hashes)\n",
    "total_hashtags = len(hashes)\n",
    "\n",
    "daca_perc = round((_DACA + _Dreamers + _ProtectDreamers)*100/total_hashtags)\n",
    "\n",
    "# Print the results\n",
    "print(\"In Congressional tweets between January 24 and 30:\")\n",
    "print(\"#DACA appeared \" + str(_DACA) + \" times\")\n",
    "print(\"#Dreamers appeared \" + str(_Dreamers) + \" times\")\n",
    "print(\"#ProtectDreamers appeared \" + str(_ProtectDreamers) + \" times\")\n",
    "print(str(daca_perc) + \"% of all hashtags were DACA related\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
